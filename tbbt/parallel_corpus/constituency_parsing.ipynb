{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import spacy\n",
    "import csv\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import spacy_stanza\n",
    "import benepar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "with open('tbbt_en_zh.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "scenes = data[(3,1)]\n",
    "scene = scenes[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(scene))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<benepar.integrations.spacy_plugin.BeneparComponent at 0x7ff1a224f5b0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Berkeley Parser\n",
    "berkeley_parser = spacy.load('en_core_web_md')\n",
    "berkeley_parser.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 14:46:52 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-03-09 14:46:52 INFO: Use device: cpu\n",
      "2022-03-09 14:46:52 INFO: Loading: tokenize\n",
      "2022-03-09 14:46:52 INFO: Loading: pos\n",
      "2022-03-09 14:46:53 INFO: Loading: lemma\n",
      "2022-03-09 14:46:53 INFO: Loading: depparse\n",
      "2022-03-09 14:46:53 INFO: Loading: sentiment\n",
      "2022-03-09 14:46:53 INFO: Loading: constituency\n",
      "2022-03-09 14:46:53 INFO: Loading: ner\n",
      "2022-03-09 14:46:54 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza_parser = spacy_stanza.load_pipeline('en')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "trf_parser = spacy.load(\"en_core_web_trf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "lg_parser = spacy.load('en_core_web_lg')\n",
    "sm_parser = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utterance': ' I just want you both to know, when I publish my findings, I won’t forget your contributions.', 'speaker': 'Sheldon', 'en_subtitles': ['Yeah, it was first come, first serve. I just want you both to know, when I publish my findings...'], 'zh_subtitles': ['是啊 先到先得嘛 第三季 第1集']}\n",
      "{'utterance': ' Great.', 'speaker': 'Howard'}\n",
      "{'utterance': ' Thanks.', 'speaker': 'Raj'}\n",
      "{'utterance': ' Of course, I can’t mention you in my Nobel acceptance speech, but when I get round to writing my memoirs you can expect a very effusive footnote, and perhaps a signed copy.', 'speaker': 'Sheldon', 'en_subtitles': [\"I can't mention you in my Nobel acceptance speech.\", 'When I write my memoirs you can expect a very effusive footnote and perhaps a signed copy.'], 'zh_subtitles': ['当然 在诺贝尔颁奖礼上发言时 我是没法提到你们的', '但是在我撰写回忆录的时候 我会在脚注中大幅提及 也许还会每人送一本 签上大名']}\n",
      "{'utterance': ' We have to tell him.', 'speaker': 'Raj', 'en_subtitles': ['- We have to tell him.'], 'zh_subtitles': ['- 我们必须告诉他']}\n",
      "{'utterance': ' Tell me what?', 'speaker': 'Sheldon', 'en_subtitles': ['- Tell me what?'], 'zh_subtitles': ['- 告诉我什么?']}\n",
      "{'utterance': ' Damn his Vulcan hearing.', 'speaker': 'Howard', 'en_subtitles': ['Damn his Vulcan hearing.', \"You are planning a party for me, aren't you?\"], 'zh_subtitles': ['他是二娃顺风耳啊', '你们哥几个打算给我庆祝庆祝是吧']}\n",
      "{'utterance': ' You fellows are planning a party for me, aren’t you?', 'speaker': 'Sheldon', 'en_subtitles': ['Okay, Sheldon, sit down.'], 'zh_subtitles': ['好吧 Sheldon 坐下']}\n",
      "{'utterance': ' Okay, Sheldon, sit down.', 'speaker': 'Howard'}\n",
      "{'utterance': ' If there’s going to be a theme, I should let you know that I don’t care for luau, toga or under the sea.', 'speaker': 'Sheldon', 'en_subtitles': [\"If there's going to be a theme, I should let you know I don't care for luau, toga or under the sea.\"], 'zh_subtitles': ['要选派对主题的话 \"夏威夷式\" \"古罗马式\"或是\"海底两万里\"都没问题']}\n",
      "{'utterance': ' Yeah, we’ll keep that in mind, look, we need to talk to you about something that happened at the North Pole.', 'speaker': 'Howard', 'en_subtitles': [\"Yeah. We'll keep that in mind.\", 'Look, we need to talk to you about something that happened at the North Pole.'], 'zh_subtitles': ['好 我们会记住的 听着...', '我们想和你谈件北极的事']}\n",
      "{'utterance': ' If this is about the night the heat went out, there’s nothing to be embarrassed about.', 'speaker': 'Sheldon', 'en_subtitles': [\"If this is about the night the heat went out there's nothing to be embarrassed about.\"], 'zh_subtitles': ['如果是说暖气坏了那晚 我倒是觉得没什么可尴尬的']}\n",
      "{'utterance': ' It’s not about that.', 'speaker': 'Raj', 'en_subtitles': [\"- It's not about that.\"], 'zh_subtitles': ['不是那件事']}\n",
      "{'utterance': ' And we agreed to never speak of it again.', 'speaker': 'Howard', 'en_subtitles': ['- We agreed to never speak of it again.'], 'zh_subtitles': ['咱不是说好再也不提嘛']}\n",
      "{'utterance': ' So we slept together naked. It was only to keep our core body temperatures from plummeting.', 'speaker': 'Sheldon', 'en_subtitles': ['So we slept together naked.', 'It was only to keep our core body temperatures from plummeting.'], 'zh_subtitles': ['我们赤身裸体睡一起', '那是为了防止体温迅速下降啊']}\n",
      "{'utterance': ' He’s speaking about it.', 'speaker': 'Howard', 'en_subtitles': [\"- He's speaking about it.\"], 'zh_subtitles': ['他又提呢']}\n",
      "{'utterance': ' For me, it was a bonding moment.', 'speaker': 'Raj', 'en_subtitles': ['- For me it was a bonding moment.'], 'zh_subtitles': ['对我来说 是增进交情的一刻']}\n",
      "{'utterance': ' Sheldon, you remember the first few weeks we were looking for magnetic monopoles and not finding anything and you were acting like an obnoxious, giant dictator?', 'speaker': 'Howard', 'en_subtitles': ['Sheldon, you remember the first few weeks we were looking for magnetic monopoles and not finding anything and you were acting like an obnoxious giant dictator?'], 'zh_subtitles': ['Sheldon 你还记得起初几个星期 我们寻觅磁单极的情形吧? 那时什么都没发现 你是那么的混世魔王']}\n",
      "{'utterance': ' I thought we were going to be gentle with him.', 'speaker': 'Raj', 'en_subtitles': ['I thought we were gonna be gentle with him.'], 'zh_subtitles': ['不是说要言辞柔和点嘛']}\n",
      "{'utterance': ' That’s why I added the tator. And then when we found our first positive data, you were so happy.', 'speaker': 'Howard', 'en_subtitles': ['That\\'s why I added the \"tator.\"', 'And when we finally got our first positive data you were so happy.'], 'zh_subtitles': ['所以我才加了\"世魔王\"仨字', '之后我们终于得到有用数据时 你是那么的欢愉']}\n",
      "{'utterance': ' Oh, yes. In the world of emoticons, I was colon, capital D.', 'speaker': 'Sheldon', 'en_subtitles': ['Oh, yes. In the world of emoticons, I was colon, capital D.'], 'zh_subtitles': ['是啊 用网络表情符就是:']}\n",
      "{'utterance': ' Well, in actuality, what your equipment detected wasn’t so much evidence of paradigm-shifting monopoles as it was… static from the electric can opener we were turning on and off.', 'speaker': 'Howard', 'en_subtitles': [\"Well, ahem, in actuality, what your equipment detected wasn't so much evidence of paradigm-shifting monopoles as it was static from the electric can opener we were turning on and off.\"], 'zh_subtitles': ['但实际上 你那些仪器探测到的 并非磁单极的连续变化... 而是电动开罐器开关的静态数据']}\n",
      "{'utterance': ' He just went colon, capital O.', 'speaker': 'Raj', 'en_subtitles': ['He just went colon, capital O.'], 'zh_subtitles': ['这回变成: O了']}\n",
      "{'utterance': ' You tampered with my experiment?', 'speaker': 'Sheldon', 'en_subtitles': ['- You tampered with my experiment?'], 'zh_subtitles': ['- 你们篡改了我的实验? - 没办法啊']}\n",
      "{'utterance': ' We had to.', 'speaker': 'Howard'}\n",
      "{'utterance': ' It was the only way to keep you from being such a huge Dickensian. You see that? I added the ensian.', 'speaker': 'Raj', 'en_subtitles': ['- We had to. It was the only way to keep you from being such a huge Dickensian.', 'You see that?', 'I added the \"ensian.\"'], 'zh_subtitles': ['你才不会那样混成狄更斯迷', '瞧见没?', '我加了\"成狄更斯迷\"']}\n",
      "{'utterance': ' Did Leonard know about this? Leonard’s my best friend in the world. Surely Leonard didn’t know.', 'speaker': 'Sheldon', 'en_subtitles': ['Did Leonard know about this?', \"Leonard's my best friend. Surely Leonard didn't know.\"], 'zh_subtitles': ['Leonard知道这件事吗?', 'Leonard是我最好的朋友 他肯定不知道']}\n",
      "{'utterance': ' Actually, it was his idea.', 'speaker': 'Howard'}\n",
      "{'utterance': ' Of course it was. The whole plan reeks of Leonard.', 'speaker': 'Sheldon', 'en_subtitles': ['- It was his idea.', '- Of course it was. The whole plan reeks of Leonard.'], 'zh_subtitles': ['实际上 那是他的主意', '没错 还有谁想得出这种馊主意']}\n"
     ]
    }
   ],
   "source": [
    "for instance in scene:\n",
    "    print(instance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeah, it was first come, first serve. I just want you both to know, when I publish my findings...\n",
      "Berkeley: [(it, 2), (I, 10), (you, 13), (both, 14), (I, 19), (my findings, 21)]\n",
      "Stanza  : [(it, 2), (I, 10), (I, 19)]\n",
      "Trf     : [(it, 2), (I, 10), (you, 13), (both, 14), (I, 19), (my findings, 21)]\n",
      "Large   : [(it, 2), (I, 10), (you, 13), (I, 19), (my findings, 21)]\n",
      "Small   : [(it, 2), (I, 10), (you, 13), (both, 14), (I, 19), (my findings, 21)]\n",
      "====================================================================================================\n",
      "I can't mention you in my Nobel acceptance speech. When I write my memoirs you can expect a very effusive footnote and perhaps a signed copy.\n",
      "Berkeley: [(I, 0), (you, 4), (my Nobel acceptance speech, 6), (I, 12), (my memoirs, 14), (you, 16), (a very effusive footnote, 19), (perhaps a signed copy, 24)]\n",
      "Stanza  : [(I, 0), (I, 12), (you, 16)]\n",
      "Trf     : [(I, 0), (you, 4), (my Nobel acceptance speech, 6), (I, 12), (my memoirs, 14), (you, 16), (a very effusive footnote, 19), (perhaps a signed copy, 24)]\n",
      "Large   : [(I, 0), (you, 4), (my Nobel acceptance speech, 6), (I, 12), (my memoirs, 14), (you, 16), (a very effusive footnote, 19), (perhaps a signed copy, 24)]\n",
      "Small   : [(I, 0), (you, 4), (my Nobel acceptance speech, 6), (I, 12), (my memoirs, 14), (you, 16), (a very effusive footnote, 19), (perhaps a signed copy, 24)]\n",
      "====================================================================================================\n",
      "- We have to tell him.\n",
      "Berkeley: [(We, 1), (him, 5)]\n",
      "Stanza  : [(We, 1)]\n",
      "Trf     : [(We, 1), (him, 5)]\n",
      "Large   : [(We, 1), (him, 5)]\n",
      "Small   : [(We, 1), (him, 5)]\n",
      "====================================================================================================\n",
      "- Tell me what?\n",
      "Berkeley: [(me, 2)]\n",
      "Stanza  : []\n",
      "Trf     : [(me, 2)]\n",
      "Large   : [(me, 2), (what, 3)]\n",
      "Small   : [(me, 2), (what, 3)]\n",
      "====================================================================================================\n",
      "Damn his Vulcan hearing. You are planning a party for me, aren't you?\n",
      "Berkeley: [(his Vulcan hearing, 1), (You, 5), (a party, 8), (me, 11), (you, 15)]\n",
      "Stanza  : [(You, 5), (you, 15)]\n",
      "Trf     : [(his Vulcan hearing, 1), (You, 5), (a party, 8), (me, 11), (you, 15)]\n",
      "Large   : [(his Vulcan hearing, 1), (You, 5), (a party, 8), (me, 11), (you, 15)]\n",
      "Small   : [(his Vulcan hearing, 1), (You, 5), (a party, 8), (me, 11), (you, 15)]\n",
      "====================================================================================================\n",
      "Okay, Sheldon, sit down.\n",
      "Berkeley: []\n",
      "Stanza  : []\n",
      "Trf     : []\n",
      "Large   : [(Sheldon, 2)]\n",
      "Small   : []\n",
      "====================================================================================================\n",
      "If there's going to be a theme, I should let you know I don't care for luau, toga or under the sea.\n",
      "Berkeley: [(a theme, 6), (I, 9), (you, 12), (I, 14), (luau, 19), (toga, 21), (the sea, 24)]\n",
      "Stanza  : [(I, 9), (I, 14)]\n",
      "Trf     : [(a theme, 6), (I, 9), (you, 12), (I, 14), (luau, 19), (toga, 21), (the sea, 24)]\n",
      "Large   : [(a theme, 6), (I, 9), (you, 12), (I, 14), (luau, 19), (toga, 21), (the sea, 24)]\n",
      "Small   : [(a theme, 6), (I, 9), (you, 12), (I, 14), (toga, 21), (the sea, 24)]\n",
      "====================================================================================================\n",
      "Yeah. We'll keep that in mind. Look, we need to talk to you about something that happened at the North Pole.\n",
      "Berkeley: [(We, 2), (that, 5), (mind, 7), (we, 11), (you, 16), (something, 18), (that, 19), (the North Pole, 22)]\n",
      "Stanza  : [(We, 2), (we, 11), (that, 19)]\n",
      "Trf     : [(We, 2), (that, 5), (mind, 7), (we, 11), (you, 16), (something, 18), (that, 19), (the North Pole, 22)]\n",
      "Large   : [(We, 2), (that, 5), (mind, 7), (we, 11), (you, 16), (something, 18), (that, 19), (the North Pole, 22)]\n",
      "Small   : [(We, 2), (that, 5), (mind, 7), (we, 11), (you, 16), (something, 18), (that, 19), (the North Pole, 22)]\n",
      "====================================================================================================\n",
      "If this is about the night the heat went out there's nothing to be embarrassed about.\n",
      "Berkeley: [(this, 1), (about the night, 3), (the heat, 6), (nothing, 12)]\n",
      "Stanza  : [(this, 1), (the heat, 6), (nothing, 12)]\n",
      "Trf     : [(this, 1), (the night, 4), (the heat, 6)]\n",
      "Large   : [(this, 1), (about the night, 3), (the heat, 6), (nothing, 12)]\n",
      "Small   : [(this, 1), (about the night, 3), (the heat, 6), (nothing, 12)]\n",
      "====================================================================================================\n",
      "- It's not about that.\n",
      "Berkeley: [(It, 1), (that, 5)]\n",
      "Stanza  : [(It, 1)]\n",
      "Trf     : [(It, 1), (that, 5)]\n",
      "Large   : [(It, 1), (that, 5)]\n",
      "Small   : [(It, 1), (that, 5)]\n",
      "====================================================================================================\n",
      "- We agreed to never speak of it again.\n",
      "Berkeley: [(We, 1), (it, 7)]\n",
      "Stanza  : [(We, 1)]\n",
      "Trf     : [(We, 1), (it, 7)]\n",
      "Large   : [(We, 1), (it, 7)]\n",
      "Small   : [(We, 1), (it, 7)]\n",
      "====================================================================================================\n",
      "So we slept together naked. It was only to keep our core body temperatures from plummeting.\n",
      "Berkeley: [(we, 1), (It, 6), (our core body temperatures, 11)]\n",
      "Stanza  : [(we, 1), (It, 6)]\n",
      "Trf     : [(we, 1), (It, 6), (our core body temperatures, 11)]\n",
      "Large   : [(we, 1), (It, 6), (our core body temperatures, 11)]\n",
      "Small   : [(we, 1), (It, 6), (our core body temperatures, 11)]\n",
      "====================================================================================================\n",
      "- He's speaking about it.\n",
      "Berkeley: [(He, 1), (it, 5)]\n",
      "Stanza  : [(He, 1)]\n",
      "Trf     : [(He, 1), (it, 5)]\n",
      "Large   : [(He, 1), (it, 5)]\n",
      "Small   : [(He, 1), (it, 5)]\n",
      "====================================================================================================\n",
      "- For me it was a bonding moment.\n",
      "Berkeley: [(me, 2), (it, 3), (a bonding moment, 5)]\n",
      "Stanza  : [(it, 3)]\n",
      "Trf     : [(me, 2), (it, 3), (a bonding moment, 5)]\n",
      "Large   : [(me, 2), (it, 3), (a bonding moment, 5)]\n",
      "Small   : [(me, 2), (it, 3), (a bonding moment, 5)]\n",
      "====================================================================================================\n",
      "Sheldon, you remember the first few weeks we were looking for magnetic monopoles and not finding anything and you were acting like an obnoxious giant dictator?\n",
      "Berkeley: [(you, 2), (the first few weeks, 4), (we, 8), (magnetic monopoles, 12), (anything, 17), (you, 19), (an obnoxious giant dictator, 23)]\n",
      "Stanza  : [(you, 2), (we, 8), (you, 19)]\n",
      "Trf     : [(you, 2), (the first few weeks, 4), (we, 8), (magnetic monopoles, 12), (anything, 17), (you, 19), (an obnoxious giant dictator, 23)]\n",
      "Large   : [(you, 2), (the first few weeks, 4), (we, 8), (magnetic monopoles, 12), (anything, 17), (you, 19), (an obnoxious giant dictator, 23)]\n",
      "Small   : [(you, 2), (the first few weeks, 4), (we, 8), (magnetic monopoles, 12), (anything, 17), (you, 19), (an obnoxious giant dictator, 23)]\n",
      "====================================================================================================\n",
      "I thought we were gonna be gentle with him.\n",
      "Berkeley: [(I, 0), (we, 2), (him, 9)]\n",
      "Stanza  : [(I, 0), (we, 2)]\n",
      "Trf     : [(I, 0), (we, 2), (him, 9)]\n",
      "Large   : [(I, 0), (we, 2), (him, 9)]\n",
      "Small   : [(I, 0), (we, 2), (him, 9)]\n",
      "====================================================================================================\n",
      "That's why I added the \"tator.\" And when we finally got our first positive data you were so happy.\n",
      "Berkeley: [(That, 0), (I, 3), (the \"tator, 5), (we, 12), (our first positive data, 15), (you, 19)]\n",
      "Stanza  : [(That, 0), (I, 3), (we, 12), (you, 19)]\n",
      "Trf     : [(That, 0), (I, 3), (the \"tator, 5), (we, 12), (our first positive data, 15), (you, 19)]\n",
      "Large   : [(That, 0), (I, 3), (the \"tator, 5), (we, 12), (our first positive data, 15), (you, 19)]\n",
      "Small   : [(That, 0), (I, 3), (the \"tator, 5), (we, 12), (our first positive data, 15), (you, 19)]\n",
      "====================================================================================================\n",
      "Oh, yes. In the world of emoticons, I was colon, capital D.\n",
      "Berkeley: [(the world, 5), (emoticons, 8), (I, 10), (colon, 12), (capital D., 14)]\n",
      "Stanza  : [(I, 10)]\n",
      "Trf     : [(the world, 5), (emoticons, 8), (I, 10), (colon, 12), (capital D., 14)]\n",
      "Large   : [(the world, 5), (emoticons, 8), (I, 10), (colon, 12), (capital D., 14)]\n",
      "Small   : [(the world, 5), (emoticons, 8), (I, 10), (colon, 12), (capital D., 14)]\n",
      "====================================================================================================\n",
      "Well, ahem, in actuality, what your equipment detected wasn't so much evidence of paradigm-shifting monopoles as it was static from the electric can opener we were turning on and off.\n",
      "Berkeley: [(ahem, 2), (actuality, 5), (what, 7), (your equipment, 8), (so much evidence, 13), (paradigm-shifting monopoles, 17), (it, 22), (the electric, 26), (we, 30)]\n",
      "Stanza  : [(what, 7), (your equipment, 8), (it, 21), (we, 29)]\n",
      "Trf     : [(actuality, 5), (what, 7), (your equipment, 8), (so much evidence, 13), (paradigm-shifting monopoles, 17), (it, 22), (static, 24), (the electric can opener, 26), (we, 30)]\n",
      "Large   : [(ahem, 2), (actuality, 5), (what, 7), (your equipment, 8), (so much evidence, 13), (paradigm-shifting monopoles, 17), (it, 22), (the electric, 26), (we, 30)]\n",
      "Small   : [(ahem, 2), (actuality, 5), (what, 7), (your equipment, 8), (so much evidence, 13), (paradigm-shifting monopoles, 17), (it, 22), (the electric, 26), (we, 30)]\n",
      "====================================================================================================\n",
      "He just went colon, capital O.\n",
      "Berkeley: [(He, 0), (capital O., 5)]\n",
      "Stanza  : [(He, 0)]\n",
      "Trf     : [(He, 0), (colon, 3), (capital O., 5)]\n",
      "Large   : [(He, 0), (colon, 3), (capital, 5)]\n",
      "Small   : [(He, 0), (colon, 3), (capital O., 5)]\n",
      "====================================================================================================\n",
      "- You tampered with my experiment?\n",
      "Berkeley: [(You, 1), (my experiment, 4)]\n",
      "Stanza  : [(You, 1)]\n",
      "Trf     : [(You, 1), (my experiment, 4)]\n",
      "Large   : [(You, 1), (my experiment, 4)]\n",
      "Small   : [(You, 1), (my experiment, 4)]\n",
      "====================================================================================================\n",
      "- We had to. It was the only way to keep you from being such a huge Dickensian. You see that? I added the \"ensian.\"\n",
      "Berkeley: [(We, 1), (It, 5), (the only way, 7), (you, 12), (such a huge Dickensian, 15), (You, 20), (that, 22), (I, 24), (the \"ensian, 26)]\n",
      "Stanza  : [(We, 1), (You, 20), (I, 24)]\n",
      "Trf     : [(We, 1), (It, 5), (the only way, 7), (you, 12), (such a huge Dickensian, 15), (You, 20), (that, 22), (I, 24), (the \"ensian, 26)]\n",
      "Large   : [(We, 1), (It, 5), (the only way, 7), (you, 12), (such a huge Dickensian, 15), (You, 20), (that, 22), (I, 24), (the \"ensian, 26)]\n",
      "Small   : [(We, 1), (It, 5), (the only way, 7), (you, 12), (such a huge Dickensian, 15), (You, 20), (that, 22), (I, 24), (the \"ensian, 26)]\n",
      "====================================================================================================\n",
      "Did Leonard know about this? Leonard's my best friend. Surely Leonard didn't know.\n",
      "Berkeley: [(Leonard, 1), (this, 4), (Leonard's my best friend, 6), (Leonard, 13)]\n",
      "Stanza  : [(Leonard, 1), (Leonard, 6), (Leonard, 13)]\n",
      "Trf     : [(Leonard, 1), (this, 4), (Leonard, 6), (my best friend, 8), (Leonard, 13)]\n",
      "Large   : [(Leonard, 1), (this, 4), (Leonard's my best friend, 6), (Leonard, 13)]\n",
      "Small   : [(Leonard, 1), (this, 4), (Leonard's my best friend, 6), (Leonard, 13)]\n",
      "====================================================================================================\n",
      "- It was his idea. - Of course it was. The whole plan reeks of Leonard.\n",
      "Berkeley: [(It, 1), (his idea, 3), (it, 9), (The whole plan, 12), (Leonard, 17)]\n",
      "Stanza  : [(It, 1), (it, 9), (The whole plan, 12)]\n",
      "Trf     : [(It, 1), (his idea, 3), (it, 9), (The whole plan, 12), (Leonard, 17)]\n",
      "Large   : [(It, 1), (his idea, 3), (it, 9), (The whole plan, 12), (Leonard, 17)]\n",
      "Small   : [(It, 1), (his idea, 3), (it, 9), (The whole plan reeks, 12), (Leonard, 17)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for instance in scene:\n",
    "    # utterance = instance['utterance']\n",
    "    if 'en_subtitles' not in instance:\n",
    "        continue\n",
    "    utterance = \" \".join(instance['en_subtitles'])\n",
    "    print(utterance)\n",
    "    print(\"Berkeley:\", [(item, item.start)for item in berkeley_parser(utterance).noun_chunks])\n",
    "    print(\"Stanza  :\", [(item, item.start)for item in stanza_parser(utterance).noun_chunks])\n",
    "    print(\"Trf     :\", [(item, item.start)for item in trf_parser(utterance).noun_chunks])\n",
    "    print(\"Large   :\", [(item, item.start)for item in lg_parser(utterance).noun_chunks])\n",
    "    print(\"Small   :\", [(item, item.start)for item in sm_parser(utterance).noun_chunks])\n",
    "    print(\"==\"*50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 14:43:48 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-03-09 14:43:48 INFO: Use device: cpu\n",
      "2022-03-09 14:43:48 INFO: Loading: tokenize\n",
      "2022-03-09 14:43:48 INFO: Loading: pos\n",
      "2022-03-09 14:43:48 INFO: Loading: lemma\n",
      "2022-03-09 14:43:48 INFO: Loading: depparse\n",
      "2022-03-09 14:43:49 INFO: Loading: sentiment\n",
      "2022-03-09 14:43:49 INFO: Loading: constituency\n",
      "2022-03-09 14:43:49 INFO: Loading: ner\n",
      "2022-03-09 14:43:50 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza_parser = spacy_stanza.load_pipeline('en')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I just want you both to know, when I publish my findings, I won’t forget your contributions.\n",
      " I 0\n",
      "I 10\n",
      "I 15\n",
      "====================================================================================================\n",
      " Great.\n",
      "====================================================================================================\n",
      " Thanks.\n",
      "====================================================================================================\n",
      " Of course, I can’t mention you in my Nobel acceptance speech, but when I get round to writing my memoirs you can expect a very effusive footnote, and perhaps a signed copy.\n",
      "I 4\n",
      "I 17\n",
      "you 24\n",
      "====================================================================================================\n",
      " We have to tell him.\n",
      " We 0\n",
      "====================================================================================================\n",
      " Tell me what?\n",
      "====================================================================================================\n",
      " Damn his Vulcan hearing.\n",
      "====================================================================================================\n",
      " You fellows are planning a party for me, aren’t you?\n",
      " You fellows 0\n",
      "you 12\n",
      "====================================================================================================\n",
      " Okay, Sheldon, sit down.\n",
      "====================================================================================================\n",
      " If there’s going to be a theme, I should let you know that I don’t care for luau, toga or under the sea.\n",
      "I 10\n",
      "I 16\n",
      "====================================================================================================\n",
      " Yeah, we’ll keep that in mind, look, we need to talk to you about something that happened at the North Pole.\n",
      "we 3\n",
      "we 12\n",
      "that 20\n",
      "====================================================================================================\n",
      " If this is about the night the heat went out, there’s nothing to be embarrassed about.\n",
      "this 2\n",
      "the heat 7\n",
      "nothing 14\n",
      "====================================================================================================\n",
      " It’s not about that.\n",
      " It 0\n",
      "====================================================================================================\n",
      " And we agreed to never speak of it again.\n",
      "we 2\n",
      "====================================================================================================\n",
      " So we slept together naked. It was only to keep our core body temperatures from plummeting.\n",
      "we 2\n",
      "It 7\n",
      "====================================================================================================\n",
      " He’s speaking about it.\n",
      " He 0\n",
      "====================================================================================================\n",
      " For me, it was a bonding moment.\n",
      "it 4\n",
      "====================================================================================================\n",
      " Sheldon, you remember the first few weeks we were looking for magnetic monopoles and not finding anything and you were acting like an obnoxious, giant dictator?\n",
      "you 3\n",
      "we 9\n",
      "you 20\n",
      "====================================================================================================\n",
      " I thought we were going to be gentle with him.\n",
      " I 0\n",
      "we 3\n",
      "====================================================================================================\n",
      " That’s why I added the tator. And then when we found our first positive data, you were so happy.\n",
      " That 0\n",
      "I 4\n",
      "we 12\n",
      "you 19\n",
      "====================================================================================================\n",
      " Oh, yes. In the world of emoticons, I was colon, capital D.\n",
      "I 11\n",
      "====================================================================================================\n",
      " Well, in actuality, what your equipment detected wasn’t so much evidence of paradigm-shifting monopoles as it was… static from the electric can opener we were turning on and off.\n",
      "what 6\n",
      "your equipment 7\n",
      "it 21\n",
      "we 30\n",
      "====================================================================================================\n",
      " He just went colon, capital O.\n",
      " He 0\n",
      "====================================================================================================\n",
      " You tampered with my experiment?\n",
      " You 0\n",
      "====================================================================================================\n",
      " We had to.\n",
      " We 0\n",
      "====================================================================================================\n",
      " It was the only way to keep you from being such a huge Dickensian. You see that? I added the ensian.\n",
      "You 16\n",
      "I 20\n",
      "====================================================================================================\n",
      " Did Leonard know about this? Leonard’s my best friend in the world. Surely Leonard didn’t know.\n",
      "Leonard 2\n",
      "Leonard 17\n",
      "====================================================================================================\n",
      " Actually, it was his idea.\n",
      "it 3\n",
      "====================================================================================================\n",
      " Of course it was. The whole plan reeks of Leonard.\n",
      "it 3\n",
      "The whole plan 6\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for instance in scene:\n",
    "    utterance = stanza_parser(instance['utterance'])\n",
    "    print(utterance)\n",
    "    for item in utterance.noun_chunks:\n",
    "        print(item, item.start)\n",
    "    print(\"==\"*50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "trf_parser = spacy.load(\"en_core_web_trf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boyuanzheng/.conda/envs/multi_coref/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I just want you both to know, when I publish my findings, I won’t forget your contributions.\n",
      "I 1\n",
      "you 4\n",
      "both 5\n",
      "I 10\n",
      "my findings 12\n",
      "I 15\n",
      "your contributions 19\n",
      "====================================================================================================\n",
      " Great.\n",
      "====================================================================================================\n",
      " Thanks.\n",
      "====================================================================================================\n",
      " Of course, I can’t mention you in my Nobel acceptance speech, but when I get round to writing my memoirs you can expect a very effusive footnote, and perhaps a signed copy.\n",
      "I 4\n",
      "you 8\n",
      "my Nobel acceptance speech 10\n",
      "I 17\n",
      "my memoirs 22\n",
      "you 24\n",
      "a very effusive footnote 27\n",
      "perhaps a signed copy 33\n",
      "====================================================================================================\n",
      " We have to tell him.\n",
      "We 1\n",
      "him 5\n",
      "====================================================================================================\n",
      " Tell me what?\n",
      "me 2\n",
      "====================================================================================================\n",
      " Damn his Vulcan hearing.\n",
      "his Vulcan hearing 2\n",
      "====================================================================================================\n",
      " You fellows are planning a party for me, aren’t you?\n",
      "You fellows 1\n",
      "a party 5\n",
      "me 8\n",
      "you 12\n",
      "====================================================================================================\n",
      " Okay, Sheldon, sit down.\n",
      "====================================================================================================\n",
      " If there’s going to be a theme, I should let you know that I don’t care for luau, toga or under the sea.\n",
      "a theme 7\n",
      "I 10\n",
      "you 13\n",
      "I 16\n",
      "luau 21\n",
      "toga 23\n",
      "the sea 26\n",
      "====================================================================================================\n",
      " Yeah, we’ll keep that in mind, look, we need to talk to you about something that happened at the North Pole.\n",
      "we 3\n",
      "that 6\n",
      "mind 8\n",
      "we 12\n",
      "you 17\n",
      "something 19\n",
      "that 20\n",
      "the North Pole 23\n",
      "====================================================================================================\n",
      " If this is about the night the heat went out, there’s nothing to be embarrassed about.\n",
      "this 2\n",
      "the heat 7\n",
      "nothing 14\n",
      "====================================================================================================\n",
      " It’s not about that.\n",
      "It 1\n",
      "that 5\n",
      "====================================================================================================\n",
      " And we agreed to never speak of it again.\n",
      "we 2\n",
      "it 8\n",
      "====================================================================================================\n",
      " So we slept together naked. It was only to keep our core body temperatures from plummeting.\n",
      "we 2\n",
      "It 7\n",
      "our core body temperatures 12\n",
      "====================================================================================================\n",
      " He’s speaking about it.\n",
      "He 1\n",
      "it 5\n",
      "====================================================================================================\n",
      " For me, it was a bonding moment.\n",
      "me 2\n",
      "it 4\n",
      "a bonding moment 6\n",
      "====================================================================================================\n",
      " Sheldon, you remember the first few weeks we were looking for magnetic monopoles and not finding anything and you were acting like an obnoxious, giant dictator?\n",
      "you 3\n",
      "the first few weeks 5\n",
      "we 9\n",
      "magnetic monopoles 13\n",
      "anything 18\n",
      "you 20\n",
      "an obnoxious, giant dictator 24\n",
      "====================================================================================================\n",
      " I thought we were going to be gentle with him.\n",
      "I 1\n",
      "we 3\n",
      "him 10\n",
      "====================================================================================================\n",
      " That’s why I added the tator. And then when we found our first positive data, you were so happy.\n",
      "That 1\n",
      "I 4\n",
      "the tator 6\n",
      "we 12\n",
      "our first positive data 14\n",
      "you 19\n",
      "====================================================================================================\n",
      " Oh, yes. In the world of emoticons, I was colon, capital D.\n",
      "the world 6\n",
      "emoticons 9\n",
      "I 11\n",
      "colon 13\n",
      "capital D. 15\n",
      "====================================================================================================\n",
      " Well, in actuality, what your equipment detected wasn’t so much evidence of paradigm-shifting monopoles as it was… static from the electric can opener we were turning on and off.\n",
      "actuality 4\n",
      "what 6\n",
      "your equipment 7\n",
      "so much evidence 12\n",
      "paradigm-shifting monopoles 16\n",
      "it 21\n",
      "static 24\n",
      "the electric can opener 26\n",
      "we 30\n",
      "====================================================================================================\n",
      " He just went colon, capital O.\n",
      "He 1\n",
      "colon 4\n",
      "capital O. 6\n",
      "====================================================================================================\n",
      " You tampered with my experiment?\n",
      "You 1\n",
      "my experiment 4\n",
      "====================================================================================================\n",
      " We had to.\n",
      "We 1\n",
      "====================================================================================================\n",
      " It was the only way to keep you from being such a huge Dickensian. You see that? I added the ensian.\n",
      "It 1\n",
      "the only way 3\n",
      "you 8\n",
      "such a huge Dickensian 11\n",
      "You 16\n",
      "that 18\n",
      "I 20\n",
      "the ensian 22\n",
      "====================================================================================================\n",
      " Did Leonard know about this? Leonard’s my best friend in the world. Surely Leonard didn’t know.\n",
      "Leonard 2\n",
      "this 5\n",
      "Leonard 7\n",
      "my best friend 9\n",
      "the world 13\n",
      "Leonard 17\n",
      "====================================================================================================\n",
      " Actually, it was his idea.\n",
      "it 3\n",
      "his idea 5\n",
      "====================================================================================================\n",
      " Of course it was. The whole plan reeks of Leonard.\n",
      "it 3\n",
      "The whole plan 6\n",
      "Leonard 11\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for instance in scene:\n",
    "    utterance = trf_parser(instance['utterance'])\n",
    "    print(utterance)\n",
    "    for item in utterance.noun_chunks:\n",
    "        print(item, item.start)\n",
    "    print(\"==\"*50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform Level-Traversal on each parsed tree\n",
    "\n",
    "For the tree traversal of Spacy Berkeley Parser\n",
    "\n",
    "1. Get Children of node: children = list(sent._.children)\n",
    "if len(children)==0, then the node if the leaf node\n",
    "\"\"\"\n",
    "def level_traversal(sentence_tree):\n",
    "    output = []\n",
    "\n",
    "    def helper(root, depth):\n",
    "        if len(output)==depth:\n",
    "            output.append([])\n",
    "\n",
    "        output[depth].append(root)\n",
    "        for child in root._.children:\n",
    "            helper(child, depth+1)\n",
    "\n",
    "    helper(sentence_tree, 0)\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(output)):\n",
    "        temp.append(output[len(output) - i - 1])\n",
    "\n",
    "    return temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "sent = list(doc.sents)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "parsed_tree = level_traversal(sent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ()\n",
      "time ()\n",
      "for ()\n",
      "action ('NP',)\n",
      "====================================================================================================\n",
      "The time ('NP',)\n",
      "for action ('PP',)\n",
      "is ()\n",
      "now ('ADVP',)\n",
      "====================================================================================================\n",
      "The time for action ('NP',)\n",
      "is now ('VP',)\n",
      ". ()\n",
      "====================================================================================================\n",
      "The time for action is now. ('S',)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for level in parsed_tree:\n",
    "    for item in level:\n",
    "        print(item, item._.labels)\n",
    "    print('=='*50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for action is now. ('S',) 0 7\n",
      "The time for action ('NP',) 0 4\n",
      "The time ('NP',) 0 2\n",
      "The () 0 1\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sent = list(doc.sents)[0]\n",
    "print(sent, sent._.labels, sent.start, sent.end)\n",
    "phrase_0 = list(sent._.children)[0]\n",
    "print(phrase_0, phrase_0._.labels, phrase_0.start, phrase_0.end)\n",
    "phrase_1 = list(phrase_0._.children)[0]\n",
    "print(phrase_1, phrase_1._.labels, phrase_1.start, phrase_1.end)\n",
    "phrase_2 = list(phrase_1._.children)[0]\n",
    "print(phrase_2, phrase_2._.labels, phrase_2.start, phrase_2.end)\n",
    "phrase_3 = list(phrase_2._.children)\n",
    "print(phrase_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    }
   ],
   "source": [
    "print(phrase_0.root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "for item in []:\n",
    "    print(item, item==None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for action is now.\n",
      "The time for action ('NP',)\n",
      "is now ('VP',)\n",
      ". ()\n",
      "====================================================================================================\n",
      "It is never too late to do something.\n",
      "It ('NP',)\n",
      "is never too late to do something ('VP',)\n",
      ". ()\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform Level_Traverse\n",
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    for item in list(sent._.children):\n",
    "        print(item, item._.labels)\n",
    "    print('=='*50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for action is now.\n"
     ]
    }
   ],
   "source": [
    "sent = list(doc.sents)[0]\n",
    "print(sent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The time for action, is now, .]\n"
     ]
    }
   ],
   "source": [
    "children = list(sent._.children)\n",
    "print(children)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time for action ('NP',) 0 4\n",
      "The time ('NP',) 0 2\n",
      "for action ('PP',) 2 4\n",
      "is now ('VP',) 4 6\n",
      "is () 4 5\n",
      "now ('ADVP',) 5 6\n",
      ". () 6 7\n"
     ]
    }
   ],
   "source": [
    "for item in children:\n",
    "    print(item, item._.labels, item.start, item.end)\n",
    "    for x in item._.children:\n",
    "        print(x, x._.labels, x.start, x.end)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}