{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import spacy\n",
    "import csv\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import benepar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "sm_parser = spacy.load('en_core_web_sm')\n",
    "berkeley_parser = spacy.load('en_core_web_md')\n",
    "berkeley_parser.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
    "# stanza_parser = spacy_stanza.load_pipeline('en')\n",
    "trf_parser = spacy.load(\"en_core_web_trf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# Load Parsed Corpus\n",
    "sm_parser = spacy.load('en_core_web_sm')\n",
    "\n",
    "with open('tbbt_en_zh.pkl', 'rb') as f_zh:\n",
    "    with open('tbbt_en_fa.pkl', 'rb') as f_fa:\n",
    "        zh = pkl.load(f_zh)\n",
    "        fa = pkl.load(f_fa)\n",
    "        inter_keys = set(zh.keys()) & set(fa.keys())\n",
    "\n",
    "with open('parsed_corpus.pkl', 'rb') as f:\n",
    "    nps = pkl.load(f)\n",
    "with open('parsed_corpus_all.pkl', 'rb') as f:\n",
    "    tags = pkl.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# Merge\n",
    "def merge_maximum_span(spans):\n",
    "    spans.sort(key=lambda x: x[1])\n",
    "    to_pop = []\n",
    "    for j, (word_0, start_idx_0, end_idx_0) in enumerate(spans):\n",
    "        for k, (word_1, start_idx_1, end_idx_1) in enumerate(spans):\n",
    "            if k==j:\n",
    "                continue\n",
    "            if (start_idx_1 >= start_idx_0) and (end_idx_1 <= end_idx_0):\n",
    "                to_pop.append(spans[k])\n",
    "    for item in to_pop:\n",
    "        if item in spans:\n",
    "            spans.remove(item)\n",
    "\n",
    "    spans.sort(key=lambda x: x[1])\n",
    "\n",
    "    return spans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# Collect Data\n",
    "output = []\n",
    "for epi_key in inter_keys:\n",
    "    if epi_key != (1,8):\n",
    "        continue\n",
    "    for i in range(len(nps[epi_key])):\n",
    "        all_sentences = []\n",
    "        all_query_spans = []\n",
    "\n",
    "        scene = nps[epi_key][i]\n",
    "        scene_tag = tags[epi_key][i]\n",
    "        j = 0\n",
    "        for utt, tag in zip(scene, scene_tag):\n",
    "            speaker = utt['speaker'].strip().strip(\"(\").strip(\")\").strip().strip(\".\").strip().strip(\":\")\n",
    "            speaker_tokens = [item.text for item in sm_parser(speaker)]\n",
    "            if \"en_subtitles\" not in utt:\n",
    "                sentence = utt['utterance']\n",
    "                utt['sm_noun_chunk'] = [(item.text, item.start, item.end) for item in sm_parser(sentence).noun_chunks]\n",
    "                utt['sm_pron'] = [(item.text,i, i+1) for i, item in enumerate(sm_parser(sentence)) if item.pos_==\"PRON\"]\n",
    "                utt['berkeley_noun_chunk'] = [(item.text, item.start, item.end) for item in berkeley_parser(sentence).noun_chunks]\n",
    "                utt['berkeley_pron'] = [(item.text,i, i+1) for i, item in enumerate(berkeley_parser(sentence)) if item.pos_==\"PRON\"]\n",
    "                utt['trf_noun_chunk'] = [(item.text, item.start, item.end) for item in trf_parser(sentence).noun_chunks]\n",
    "                utt['trf_pron'] = [(item.text,i, i+1) for i, item in enumerate(trf_parser(sentence)) if item.pos_==\"PRON\"]\n",
    "            else:\n",
    "                sentence = \" \".join([x.strip().lstrip('-').lstrip().lstrip('.').lstrip() for x in utt['en_subtitles']])\n",
    "            sentence_token = [item.text for item in sm_parser(sentence)]\n",
    "            noun_phrase = merge_maximum_span(list(set(utt['sm_noun_chunk']) | set(utt['berkeley_noun_chunk']) | set(utt['trf_noun_chunk'])))\n",
    "            pron = merge_maximum_span(list(set(utt['sm_pron']) | set(utt['berkeley_pron']) | set(utt['trf_pron'])))\n",
    "            mention = list(set(noun_phrase)|set(pron))\n",
    "            mention.sort(key=lambda x: x[1])\n",
    "\n",
    "            all_sentences.append(speaker_tokens + [\":\"] + sentence_token)\n",
    "            for span in mention:\n",
    "                all_query_spans.append({\n",
    "                        \"sentenceIndex\": j,\n",
    "                        \"startToken\": span[1] + len(speaker_tokens) + 1,\n",
    "                        \"endToken\": span[2] + len(speaker_tokens) + 1\n",
    "                    })\n",
    "            j+=1\n",
    "        output.append({\n",
    "            \"sentences\": all_sentences,\n",
    "            \"querySpans\": all_query_spans,\n",
    "            \"candidateSpans\": all_query_spans,\n",
    "            \"clickSpans\": all_query_spans,\n",
    "            })\n",
    "\n",
    "with open('sample_annotate_epi_1_8_new.csv', \"w\", encoding=\"utf-8\") as csv_fh:\n",
    "        fieldnames = ['json_data']\n",
    "        writer = csv.DictWriter(csv_fh, fieldnames, lineterminator='\\n')\n",
    "        writer.writeheader()\n",
    "        for line in output:\n",
    "            writer.writerow({'json_data': json.dumps(line)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}