{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ipydagred3\n",
    "# install benepar and download benepar_fr\n",
    "\n",
    "import ipydagred3\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "from spacy import displacy\n",
    "from benepar.spacy_plugin import BeneparComponent\n",
    "\n",
    "nlp = spacy.load(\"fr\")\n",
    "nlp.add_pipe(BeneparComponent('benepar_fr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to complete this dict and PR\n",
    "\n",
    "tooltips = {\n",
    "    \"NP-SUJ\": \"Nom propre sujet\",\n",
    "    \"PONCT\": \"Ponctuation\",\n",
    "    \"VN\": \"Noyau verbal\",\n",
    "    \"ADV\": \"Adverbe\",\n",
    "    \"AP-ATS\": \"attribut du sujet\",\n",
    "    \"NC\": \"Nom commun\",\n",
    "    \"DET\": \"Déterminant\",\n",
    "    \"V\": \"Verb\",\n",
    "    \"SENT\": \"Phrase racine\",\n",
    "    \"NP-OBJ\": \"Nom propre, objet\",\n",
    "    \"Srel\": \"Subordonnée relative\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "try:\n",
    "    nlp.remove_pipe(\"constituency_parser\")\n",
    "    Span.remove_extension(\"constituency\")\n",
    "    Span.remove_extension(\"show_constituency\")\n",
    "    Span.remove_extension(\"search_constituency\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def _flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "\n",
    "flatten = lambda l: list(_flatten(l))\n",
    "\n",
    "class ConstituencyParser():\n",
    "    name = \"constituency_parser\"\n",
    "\n",
    "    def __init__(self):\n",
    "        Span.set_extension(\"constituency\", default=None)\n",
    "        Span.set_extension(\"show_constituency\", default=None)\n",
    "        Span.set_extension(\"search_constituency\", default=None)\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        for sent in doc.sents:\n",
    "            nodes, parsed  = self.processConstituency(sent._.parse_string)\n",
    "            sent._.set(\"show_constituency\", lambda: self.showDependencyGraph(nodes, parsed))\n",
    "            sent._.set(\"search_constituency\", lambda _type: self.find(_type, parsed, sent))\n",
    "        return doc\n",
    "\n",
    "    def processConstituency(self, pStr):\n",
    "        nodes = []\n",
    "        cur = \"\";\n",
    "        stack = [];\n",
    "        nid = 0;\n",
    "        wordIndex = 0\n",
    "        for i in range(len(pStr)):\n",
    "            if(pStr[i] == ' ' or pStr[i] == '\\n'):\n",
    "                if (len(cur) > 0): \n",
    "                    newNode = {\n",
    "                        \"nodeID\": nid,\n",
    "                        \"nodeType\": \"Internal\",\n",
    "                        \"name\": cur,\n",
    "                        \"children\": []\n",
    "                    }\n",
    "                    cur = \"\";\n",
    "                    nid += 1;\n",
    "                    if (len(stack) > 0):\n",
    "                        stack[len(stack) - 1][\"children\"].append(newNode);\n",
    "                    stack.append(newNode);\n",
    "                    nodes.append(newNode)\n",
    "            elif pStr[i] == ')':\n",
    "                if (len(cur) > 0):\n",
    "                    newNode = {\n",
    "                        \"nodeID\": nid,\n",
    "                        \"nodeType\": \"Leaf\",\n",
    "                        \"name\": cur,\n",
    "                        \"wordIndex\": wordIndex,\n",
    "                        \"children\": []\n",
    "                    }\n",
    "                    cur = \"\";\n",
    "                    nid += 1;\n",
    "                    wordIndex += 1;\n",
    "                    stack[len(stack) - 1][\"children\"].append(newNode);\n",
    "                    nodes.append(newNode)\n",
    "                    stack.pop();\n",
    "                else:\n",
    "                    if (len(stack) == 1):\n",
    "                        root = stack[0]\n",
    "                    stack.pop();\n",
    "            elif pStr[i] == '(':\n",
    "                continue\n",
    "            else:\n",
    "                cur = cur + pStr[i];\n",
    "        return nodes, root\n",
    "\n",
    "    def showDependencyGraph(self, nodes, parsed):\n",
    "        g = ipydagred3.Graph()\n",
    "        for node in nodes:\n",
    "            g.setNode(str(node[\"nodeID\"]),\n",
    "                      label=node[\"name\"],\n",
    "                      tooltip=tooltips[node[\"name\"]] if node[\"name\"] in tooltips else node[\"name\"],\n",
    "                      rx=5,\n",
    "                      ry=5,\n",
    "                      style=\"fill: \" + (\"white\" if len(node[\"children\"]) else \"#00bcd4\"));\n",
    "\n",
    "        def setEdge(parent):\n",
    "            for i in range(len(parent[\"children\"])):\n",
    "                g.setEdge(str(parent[\"nodeID\"]), str(parent[\"children\"][i][\"nodeID\"]))\n",
    "                setEdge(parent[\"children\"][i])\n",
    "\n",
    "        setEdge(parsed)\n",
    "        widget = ipydagred3.DagreD3Widget(graph=g)\n",
    "        return display(widget)\n",
    "\n",
    "    def getWordIndex(self, node):\n",
    "        return [self.getWordIndex(childNode) for childNode in node[\"children\"]] if node[\"nodeType\"] != \"Leaf\" else node[\"wordIndex\"]\n",
    "\n",
    "    def getSpan(self, node):\n",
    "        return\n",
    "    \n",
    "    def getString(self, node):\n",
    "        return ' '.join([self.getString(childNode) for childNode in node[\"children\"]]) if node[\"nodeType\"] != \"Leaf\" else node[\"name\"]\n",
    "\n",
    "    def search(self, _types, node):\n",
    "        fltn = lambda l: [item for sublist in l for item in sublist]\n",
    "        types = [child for child in node[\"children\"] if child[\"name\"] in _types]\n",
    "        others = fltn([self.search(_types, child) for child in node[\"children\"]])\n",
    "        return types+others\n",
    "\n",
    "    def find(self, _types, node, sent):\n",
    "        spans = []\n",
    "        strings = []\n",
    "        for _node in self.search(_types, node):\n",
    "            indexes = flatten([x for x in self.getWordIndex(_node)])\n",
    "            span = sent[min(indexes): max(indexes)+1]\n",
    "            spans.append(span)\n",
    "            strings.append(self.getString(_node))\n",
    "        return spans\n",
    "        \n",
    "\n",
    "# add constituencyParser to spacy pipeline\n",
    "constituencyParser = ConstituencyParser()\n",
    "nlp.add_pipe(constituencyParser, last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "\n",
      "SENTENCE  :  le petit chat joue dans le grand jardin vert.\n",
      "SUBJECTs  :  [le petit chat]\n",
      "OBJECTs   :  []\n",
      "VERBS     :  [joue]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62be43295f5b427788fb139f7154f510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DagreD3Widget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"le petit chat joue dans le grand jardin vert.\")\n",
    "sent = list(doc.sents)[0]\n",
    "print(\"=========================\\n\")\n",
    "print(\"SENTENCE  : \", sent)\n",
    "print(\"SUBJECTs  : \", sent._.search_constituency([\"NP-SUJ\"]))\n",
    "print(\"OBJECTs   : \", sent._.search_constituency([\"NP-OBJ\"]))\n",
    "print(\"VERBS     : \", sent._.search_constituency([\"VN\"]))\n",
    "sent._.show_constituency()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
